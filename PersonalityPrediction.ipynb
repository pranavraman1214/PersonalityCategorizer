{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalitycsv = pd.read_csv(\"mbti_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "types = personalitycsv['type']\n",
    "uncleanedposts = personalitycsv['posts']\n",
    "cleanedposts = []\n",
    "counter = 0 \n",
    "newtype = []\n",
    "newposts = []\n",
    "for s in uncleanedposts: \n",
    "    cleaned = s.split(\"|||\")\n",
    "    created = []\n",
    "    for x in cleaned: \n",
    "        text = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', x)\n",
    "        if len(text.strip()) < 3: \n",
    "              continue \n",
    "        else: \n",
    "              created.append(text.strip())\n",
    "    for x in created: \n",
    "        newtype.append(types[counter])\n",
    "        newposts.append(x)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Types</th>\n",
       "      <th>id</th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>enfp and intj moments    sportscenter not top ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>On repeat for most of today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>May the PerC Experience immerse you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>The last thing my INFJ friend posted on his fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410455</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>I was going to close my facebook a few months ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410456</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>30 Seconds to Mars - All of my collections. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410457</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>I have seen it, and i agree. I did actually th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410458</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>Ok so i have just watched Underworld 4 (Awaken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410459</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>I would never want to turn off my emotions. so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410460 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Types  id                                              Posts\n",
       "0       INFJ   8  enfp and intj moments    sportscenter not top ...\n",
       "1       INFJ   8  What has been the most life-changing experienc...\n",
       "2       INFJ   8                       On repeat for most of today.\n",
       "3       INFJ   8               May the PerC Experience immerse you.\n",
       "4       INFJ   8  The last thing my INFJ friend posted on his fa...\n",
       "...      ...  ..                                                ...\n",
       "410455  INFP   9  I was going to close my facebook a few months ...\n",
       "410456  INFP   9  30 Seconds to Mars - All of my collections. It...\n",
       "410457  INFP   9  I have seen it, and i agree. I did actually th...\n",
       "410458  INFP   9  Ok so i have just watched Underworld 4 (Awaken...\n",
       "410459  INFP   9  I would never want to turn off my emotions. so...\n",
       "\n",
       "[410460 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaneddf = pd.DataFrame() \n",
    "cleaneddf['Types'] = newtype\n",
    "cleaneddf = cleaneddf.assign(id=(cleaneddf['Types']).astype('category').cat.codes)\n",
    "cleaneddf['Posts']=newposts\n",
    "cleaneddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training Sentiment Model To Assess Posts \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyze = SentimentIntensityAnalyzer()\n",
    "pos = []\n",
    "neg = []\n",
    "neu = []\n",
    "compound = []\n",
    "for x in cleaneddf['Posts']:\n",
    "    analyzed = analyze.polarity_scores(x)\n",
    "    pos.append(analyzed['pos'])\n",
    "    neg.append(analyzed['neg'])\n",
    "    neu.append(analyzed['neu'])\n",
    "    compound.append(analyzed['compound'])\n",
    "\n",
    "cleaneddf['Positive']=pos\n",
    "cleaneddf['Negative']=neg\n",
    "cleaneddf['Neutral']=neu\n",
    "cleaneddf['Compound']=compound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import gensim\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.840B.300d.txt'\n",
    "word2vec_output_file = 'glove.840B.300d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#If File not located for pickle run this\n",
    "from gensim.models import KeyedVectors\n",
    "filename = 'glove.840B.300d.txt.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "pickle.dump(model, open( \"model.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "model = pickle.load( open( \"model.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "charcounts = []\n",
    "wordcounts = []\n",
    "numbercounts = []\n",
    "allmodels = []\n",
    "for x in cleaneddf['Posts']: \n",
    "    spliter = x.split()\n",
    "    newmodel = np.zeros(300)\n",
    "    first = True\n",
    "    for y in spliter:\n",
    "        y = re.sub(r'[^\\w\\s]','',y)\n",
    "        y = y.lower()\n",
    "        try:\n",
    "            if first:\n",
    "                newmodel = np.array(model[str(y)])\n",
    "                first = False\n",
    "            else: \n",
    "                newmodel += np.array(model[str(y)]) \n",
    "        except:\n",
    "            continue\n",
    "    allmodels.append(newmodel/len(spliter))\n",
    "    numbercounts.append(len([x for x in x.split() if x.isdigit()]))\n",
    "    wordcounts.append(len(spliter))\n",
    "    charcounts.append(len(x))\n",
    "cleaneddf['Vectors'] = allmodels\n",
    "cleaneddf['CharCounts'] = charcounts\n",
    "cleaneddf['NumberCounts'] = numbercounts\n",
    "cleaneddf['WordCounts'] = wordcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "allvectors = []\n",
    "for i in range(300):\n",
    "    empty = []\n",
    "    allvectors.append(empty)\n",
    "for vector in cleaneddf['Vectors']:\n",
    "    for i in range(300): \n",
    "        allvectors[i].append(vector[i])    \n",
    "\n",
    "for i in range(300):\n",
    "    name = \"Vector\" + str(i)\n",
    "    cleaneddf[name] = allvectors[i]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Types</th>\n",
       "      <th>id</th>\n",
       "      <th>Posts</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Compound</th>\n",
       "      <th>CharCounts</th>\n",
       "      <th>NumberCounts</th>\n",
       "      <th>WordCounts</th>\n",
       "      <th>...</th>\n",
       "      <th>Vector290</th>\n",
       "      <th>Vector291</th>\n",
       "      <th>Vector292</th>\n",
       "      <th>Vector293</th>\n",
       "      <th>Vector294</th>\n",
       "      <th>Vector295</th>\n",
       "      <th>Vector296</th>\n",
       "      <th>Vector297</th>\n",
       "      <th>Vector298</th>\n",
       "      <th>Vector299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>enfp and intj moments    sportscenter not top ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.706</td>\n",
       "      <td>-0.3252</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056108</td>\n",
       "      <td>-0.164767</td>\n",
       "      <td>-0.003561</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.101166</td>\n",
       "      <td>0.147577</td>\n",
       "      <td>-0.051816</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>0.082892</td>\n",
       "      <td>-0.078360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206936</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-0.106586</td>\n",
       "      <td>-0.132355</td>\n",
       "      <td>0.153329</td>\n",
       "      <td>0.067408</td>\n",
       "      <td>-0.021258</td>\n",
       "      <td>0.051582</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>-0.030550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>On repeat for most of today.</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.205930</td>\n",
       "      <td>-0.171407</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>-0.185498</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.028441</td>\n",
       "      <td>-0.097105</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.116196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>May the PerC Experience immerse you.</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216144</td>\n",
       "      <td>0.045832</td>\n",
       "      <td>-0.170137</td>\n",
       "      <td>-0.002519</td>\n",
       "      <td>0.065560</td>\n",
       "      <td>-0.067423</td>\n",
       "      <td>-0.240428</td>\n",
       "      <td>0.070806</td>\n",
       "      <td>0.127976</td>\n",
       "      <td>-0.004138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>The last thing my INFJ friend posted on his fa...</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.640</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099172</td>\n",
       "      <td>0.030649</td>\n",
       "      <td>0.107528</td>\n",
       "      <td>-0.086214</td>\n",
       "      <td>0.078186</td>\n",
       "      <td>-0.070215</td>\n",
       "      <td>0.032399</td>\n",
       "      <td>0.093196</td>\n",
       "      <td>-0.047283</td>\n",
       "      <td>0.185068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410455</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>I was going to close my facebook a few months ...</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219012</td>\n",
       "      <td>0.073492</td>\n",
       "      <td>0.065388</td>\n",
       "      <td>0.019547</td>\n",
       "      <td>0.137126</td>\n",
       "      <td>-0.073177</td>\n",
       "      <td>0.013745</td>\n",
       "      <td>-0.090762</td>\n",
       "      <td>0.050335</td>\n",
       "      <td>0.162630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410456</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>30 Seconds to Mars - All of my collections. It...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152720</td>\n",
       "      <td>0.046057</td>\n",
       "      <td>0.063996</td>\n",
       "      <td>0.007415</td>\n",
       "      <td>0.063590</td>\n",
       "      <td>-0.099732</td>\n",
       "      <td>-0.054618</td>\n",
       "      <td>-0.003745</td>\n",
       "      <td>-0.060029</td>\n",
       "      <td>0.083143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410457</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>I have seen it, and i agree. I did actually th...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200789</td>\n",
       "      <td>0.064960</td>\n",
       "      <td>-0.039382</td>\n",
       "      <td>-0.041747</td>\n",
       "      <td>0.148716</td>\n",
       "      <td>-0.048417</td>\n",
       "      <td>-0.080719</td>\n",
       "      <td>-0.013402</td>\n",
       "      <td>0.124531</td>\n",
       "      <td>0.174318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410458</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>Ok so i have just watched Underworld 4 (Awaken...</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.8218</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235097</td>\n",
       "      <td>0.051023</td>\n",
       "      <td>-0.022789</td>\n",
       "      <td>-0.098781</td>\n",
       "      <td>0.156418</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>-0.060064</td>\n",
       "      <td>-0.072731</td>\n",
       "      <td>0.069270</td>\n",
       "      <td>0.100613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410459</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>I would never want to turn off my emotions. so...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.880</td>\n",
       "      <td>-0.1182</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264817</td>\n",
       "      <td>0.046290</td>\n",
       "      <td>-0.054886</td>\n",
       "      <td>-0.069837</td>\n",
       "      <td>0.109587</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>-0.003390</td>\n",
       "      <td>0.074028</td>\n",
       "      <td>0.104892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410460 rows Ã— 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Types  id                                              Posts  Positive  \\\n",
       "0       INFJ   8  enfp and intj moments    sportscenter not top ...     0.000   \n",
       "1       INFJ   8  What has been the most life-changing experienc...     0.000   \n",
       "2       INFJ   8                       On repeat for most of today.     0.000   \n",
       "3       INFJ   8               May the PerC Experience immerse you.     0.000   \n",
       "4       INFJ   8  The last thing my INFJ friend posted on his fa...     0.180   \n",
       "...      ...  ..                                                ...       ...   \n",
       "410455  INFP   9  I was going to close my facebook a few months ...     0.171   \n",
       "410456  INFP   9  30 Seconds to Mars - All of my collections. It...     0.000   \n",
       "410457  INFP   9  I have seen it, and i agree. I did actually th...     0.072   \n",
       "410458  INFP   9  Ok so i have just watched Underworld 4 (Awaken...     0.202   \n",
       "410459  INFP   9  I would never want to turn off my emotions. so...     0.000   \n",
       "\n",
       "        Negative  Neutral  Compound  CharCounts  NumberCounts  WordCounts  \\\n",
       "0          0.294    0.706   -0.3252          65             0          10   \n",
       "1          0.000    1.000    0.0000          61             0          10   \n",
       "2          0.000    1.000    0.0000          28             0           6   \n",
       "3          0.000    1.000    0.0000          36             0           6   \n",
       "4          0.180    0.640   -0.2500         107             0          19   \n",
       "...          ...      ...       ...         ...           ...         ...   \n",
       "410455     0.000    0.829    0.7783         193             0          40   \n",
       "410456     0.000    1.000    0.0000          85             1          18   \n",
       "410457     0.000    0.928    0.3612         199             0          38   \n",
       "410458     0.000    0.798    0.8218         200             1          41   \n",
       "410459     0.120    0.880   -0.1182         112             0          23   \n",
       "\n",
       "        ...  Vector290  Vector291  Vector292  Vector293  Vector294  Vector295  \\\n",
       "0       ...   0.056108  -0.164767  -0.003561   0.040664   0.101166   0.147577   \n",
       "1       ...  -0.206936   0.000180  -0.106586  -0.132355   0.153329   0.067408   \n",
       "2       ...  -0.205930  -0.171407   0.019444  -0.185498   0.014593  -0.031991   \n",
       "3       ...  -0.216144   0.045832  -0.170137  -0.002519   0.065560  -0.067423   \n",
       "4       ...  -0.099172   0.030649   0.107528  -0.086214   0.078186  -0.070215   \n",
       "...     ...        ...        ...        ...        ...        ...        ...   \n",
       "410455  ...  -0.219012   0.073492   0.065388   0.019547   0.137126  -0.073177   \n",
       "410456  ...  -0.152720   0.046057   0.063996   0.007415   0.063590  -0.099732   \n",
       "410457  ...  -0.200789   0.064960  -0.039382  -0.041747   0.148716  -0.048417   \n",
       "410458  ...  -0.235097   0.051023  -0.022789  -0.098781   0.156418   0.001369   \n",
       "410459  ...  -0.264817   0.046290  -0.054886  -0.069837   0.109587   0.002011   \n",
       "\n",
       "        Vector296  Vector297  Vector298  Vector299  \n",
       "0       -0.051816   0.038400   0.082892  -0.078360  \n",
       "1       -0.021258   0.051582   0.005985  -0.030550  \n",
       "2       -0.028441  -0.097105   0.016200   0.116196  \n",
       "3       -0.240428   0.070806   0.127976  -0.004138  \n",
       "4        0.032399   0.093196  -0.047283   0.185068  \n",
       "...           ...        ...        ...        ...  \n",
       "410455   0.013745  -0.090762   0.050335   0.162630  \n",
       "410456  -0.054618  -0.003745  -0.060029   0.083143  \n",
       "410457  -0.080719  -0.013402   0.124531   0.174318  \n",
       "410458  -0.060064  -0.072731   0.069270   0.100613  \n",
       "410459   0.004405  -0.003390   0.074028   0.104892  \n",
       "\n",
       "[410460 rows x 310 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaneddf = cleaneddf.drop(['Vectors'],axis = 1)\n",
    "cleaneddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cleaneddf.drop(['Types','id','Posts'],axis = 1)\n",
    "y = cleaneddf['id']\n",
    "labels = cleaneddf['Types']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Figures Out Relevant Features and Removes Irrelevant Ones\n",
    "import statsmodels.api as sm\n",
    "cols = list(x.columns)\n",
    "pmax = 1\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = x[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(y,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cleaneddf[['Positive', 'Neutral', 'Compound', 'CharCounts', 'NumberCounts', 'WordCounts', 'Vector3', 'Vector5', 'Vector6', 'Vector9', 'Vector10', 'Vector12', 'Vector16', 'Vector22', 'Vector23', 'Vector27', 'Vector28', 'Vector30', 'Vector31', 'Vector32', 'Vector33', 'Vector36', 'Vector37', 'Vector38', 'Vector40', 'Vector46', 'Vector49', 'Vector50', 'Vector52', 'Vector55', 'Vector58', 'Vector65', 'Vector66', 'Vector69', 'Vector70', 'Vector72', 'Vector73', 'Vector79', 'Vector83', 'Vector86', 'Vector87', 'Vector88', 'Vector91', 'Vector94', 'Vector96', 'Vector97', 'Vector98', 'Vector100', 'Vector102', 'Vector103', 'Vector105', 'Vector107', 'Vector113', 'Vector114', 'Vector115', 'Vector116', 'Vector123', 'Vector124', 'Vector125', 'Vector126', 'Vector128', 'Vector130', 'Vector131', 'Vector134', 'Vector138', 'Vector142', 'Vector143', 'Vector145', 'Vector148', 'Vector154', 'Vector155', 'Vector159', 'Vector160', 'Vector162', 'Vector164', 'Vector166', 'Vector169', 'Vector172', 'Vector174', 'Vector175', 'Vector176', 'Vector177', 'Vector179', 'Vector180', 'Vector182', 'Vector184', 'Vector187', 'Vector188', 'Vector189', 'Vector190', 'Vector192', 'Vector196', 'Vector198', 'Vector201', 'Vector204', 'Vector205', 'Vector207', 'Vector211', 'Vector214', 'Vector221', 'Vector222', 'Vector226', 'Vector229', 'Vector236', 'Vector238', 'Vector244', 'Vector247', 'Vector249', 'Vector253', 'Vector255', 'Vector262', 'Vector263', 'Vector264', 'Vector265', 'Vector267', 'Vector268', 'Vector270', 'Vector272', 'Vector275', 'Vector279', 'Vector280', 'Vector282', 'Vector286', 'Vector287', 'Vector288', 'Vector289', 'Vector291', 'Vector292', 'Vector294', 'Vector297']]\n",
    "y = cleaneddf['id']\n",
    "labels = cleaneddf['Types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print(logreg.score(X_train, y_train))\n",
    "print(logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "print(gnb.score(X_train, y_train))\n",
    "print(gnb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dct = DecisionTreeClassifier()\n",
    "dct.fit(X_train,y_train)\n",
    "print(dct.score(X_train, y_train))\n",
    "print(dct.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "print(rfc.score(X_train, y_train))\n",
    "print(rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train,y_train)\n",
    "print(ada.score(X_train, y_train))\n",
    "print(ada.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "print(lr.score(X_train, y_train))\n",
    "print(lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "cb = BernoulliNB()\n",
    "cb.fit(X_train, y_train)\n",
    "print(cb.score(X_train, y_train))\n",
    "print(cb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.RidgeCV()\n",
    "reg.fit(X_train, y_train)\n",
    "print(reg.score(X_train, y_train))\n",
    "print(reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Lasso()\n",
    "reg.fit(X_train, y_train)\n",
    "print(reg.score(X_train, y_train))\n",
    "print(reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
