{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalitycsv = pd.read_csv(\"mbti_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "types = personalitycsv['type']\n",
    "uncleanedposts = personalitycsv['posts']\n",
    "cleanedposts = []\n",
    "counter = 0 \n",
    "newtype = []\n",
    "newposts = []\n",
    "for s in uncleanedposts: \n",
    "    cleaned = s.split(\"|||\")\n",
    "    created = []\n",
    "    for x in cleaned: \n",
    "        text = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', x)\n",
    "        if len(text.strip()) < 3: \n",
    "              continue \n",
    "        else: \n",
    "              created.append(text.strip())\n",
    "    for x in created: \n",
    "        newtype.append(types[counter])\n",
    "        newposts.append(x)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Types</th>\n",
       "      <th>id</th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>enfp and intj moments    sportscenter not top ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>On repeat for most of today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>May the PerC Experience immerse you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>The last thing my INFJ friend posted on his fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410455</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>I was going to close my facebook a few months ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410456</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>30 Seconds to Mars - All of my collections. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410457</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>I have seen it, and i agree. I did actually th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410458</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>Ok so i have just watched Underworld 4 (Awaken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410459</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>I would never want to turn off my emotions. so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410460 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Types  id                                              Posts\n",
       "0       INFJ   8  enfp and intj moments    sportscenter not top ...\n",
       "1       INFJ   8  What has been the most life-changing experienc...\n",
       "2       INFJ   8                       On repeat for most of today.\n",
       "3       INFJ   8               May the PerC Experience immerse you.\n",
       "4       INFJ   8  The last thing my INFJ friend posted on his fa...\n",
       "...      ...  ..                                                ...\n",
       "410455  INFP   9  I was going to close my facebook a few months ...\n",
       "410456  INFP   9  30 Seconds to Mars - All of my collections. It...\n",
       "410457  INFP   9  I have seen it, and i agree. I did actually th...\n",
       "410458  INFP   9  Ok so i have just watched Underworld 4 (Awaken...\n",
       "410459  INFP   9  I would never want to turn off my emotions. so...\n",
       "\n",
       "[410460 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaneddf = pd.DataFrame() \n",
    "cleaneddf['Types'] = newtype\n",
    "cleaneddf = cleaneddf.assign(id=(cleaneddf['Types']).astype('category').cat.codes)\n",
    "cleaneddf['Posts']=newposts\n",
    "cleaneddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training Sentiment Model To Assess Posts \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyze = SentimentIntensityAnalyzer()\n",
    "pos = []\n",
    "neg = []\n",
    "neu = []\n",
    "compound = []\n",
    "for x in cleaneddf['Posts']:\n",
    "    analyzed = analyze.polarity_scores(x)\n",
    "    pos.append(analyzed['pos'])\n",
    "    neg.append(analyzed['neg'])\n",
    "    neu.append(analyzed['neu'])\n",
    "    compound.append(analyzed['compound'])\n",
    "\n",
    "cleaneddf['Positive']=pos\n",
    "cleaneddf['Negative']=neg\n",
    "cleaneddf['Neutral']=neu\n",
    "cleaneddf['Compound']=compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.840B.300d.txt'\n",
    "word2vec_output_file = 'glove.840B.300d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If File not located for pickle run this\n",
    "from gensim.models import KeyedVectors\n",
    "filename = 'glove.840B.300d.txt.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "pickle.dump(model, open( \"model.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "model = pickle.load( open( \"model.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "charcounts = []\n",
    "wordcounts = []\n",
    "numbercounts = []\n",
    "allmodels = []\n",
    "for x in cleaneddf['Posts']: \n",
    "    spliter = x.split()\n",
    "    newmodel = np.zeros(300)\n",
    "    first = True\n",
    "    for y in spliter:\n",
    "        y = re.sub(r'[^\\w\\s]','',y)\n",
    "        y = y.lower()\n",
    "        try:\n",
    "            if first:\n",
    "                newmodel = np.array(model[str(y)])\n",
    "                first = False\n",
    "            else: \n",
    "                newmodel += np.array(model[str(y)]) \n",
    "        except:\n",
    "            continue\n",
    "    allmodels.append(newmodel/len(spliter))\n",
    "    numbercounts.append(len([x for x in x.split() if x.isdigit()]))\n",
    "    wordcounts.append(len(spliter))\n",
    "    charcounts.append(len(x))\n",
    "cleaneddf['Vectors'] = allmodels\n",
    "cleaneddf['CharCounts'] = charcounts\n",
    "cleaneddf['NumberCounts'] = numbercounts\n",
    "cleaneddf['WordCounts'] = wordcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "allvectors = []\n",
    "for i in range(300):\n",
    "    empty = []\n",
    "    allvectors.append(empty)\n",
    "for vector in cleaneddf['Vectors']:\n",
    "    for i in range(300): \n",
    "        allvectors[i].append(vector[i])    \n",
    "\n",
    "for i in range(300):\n",
    "    name = \"Vector\" + str(i)\n",
    "    cleaneddf[name] = allvectors[i]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Types</th>\n",
       "      <th>id</th>\n",
       "      <th>Posts</th>\n",
       "      <th>CharCounts</th>\n",
       "      <th>NumberCounts</th>\n",
       "      <th>WordCounts</th>\n",
       "      <th>Vector0</th>\n",
       "      <th>Vector1</th>\n",
       "      <th>Vector2</th>\n",
       "      <th>Vector3</th>\n",
       "      <th>...</th>\n",
       "      <th>Vector290</th>\n",
       "      <th>Vector291</th>\n",
       "      <th>Vector292</th>\n",
       "      <th>Vector293</th>\n",
       "      <th>Vector294</th>\n",
       "      <th>Vector295</th>\n",
       "      <th>Vector296</th>\n",
       "      <th>Vector297</th>\n",
       "      <th>Vector298</th>\n",
       "      <th>Vector299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>enfp and intj moments    sportscenter not top ...</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.048666</td>\n",
       "      <td>0.101238</td>\n",
       "      <td>-0.126730</td>\n",
       "      <td>-0.103111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056108</td>\n",
       "      <td>-0.164767</td>\n",
       "      <td>-0.003561</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.101166</td>\n",
       "      <td>0.147577</td>\n",
       "      <td>-0.051816</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>0.082892</td>\n",
       "      <td>-0.078360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.069644</td>\n",
       "      <td>0.287454</td>\n",
       "      <td>-0.003381</td>\n",
       "      <td>-0.055506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206936</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-0.106586</td>\n",
       "      <td>-0.132355</td>\n",
       "      <td>0.153329</td>\n",
       "      <td>0.067408</td>\n",
       "      <td>-0.021258</td>\n",
       "      <td>0.051582</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>-0.030550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>On repeat for most of today.</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.109645</td>\n",
       "      <td>0.309563</td>\n",
       "      <td>-0.250297</td>\n",
       "      <td>-0.100388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.205930</td>\n",
       "      <td>-0.171407</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>-0.185498</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.028441</td>\n",
       "      <td>-0.097105</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.116196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>May the PerC Experience immerse you.</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.262368</td>\n",
       "      <td>0.025354</td>\n",
       "      <td>-0.132030</td>\n",
       "      <td>-0.066374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216144</td>\n",
       "      <td>0.045832</td>\n",
       "      <td>-0.170137</td>\n",
       "      <td>-0.002519</td>\n",
       "      <td>0.065560</td>\n",
       "      <td>-0.067423</td>\n",
       "      <td>-0.240428</td>\n",
       "      <td>0.070806</td>\n",
       "      <td>0.127976</td>\n",
       "      <td>-0.004138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>The last thing my INFJ friend posted on his fa...</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.070736</td>\n",
       "      <td>0.184186</td>\n",
       "      <td>-0.126542</td>\n",
       "      <td>0.127377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099172</td>\n",
       "      <td>0.030649</td>\n",
       "      <td>0.107528</td>\n",
       "      <td>-0.086214</td>\n",
       "      <td>0.078186</td>\n",
       "      <td>-0.070215</td>\n",
       "      <td>0.032399</td>\n",
       "      <td>0.093196</td>\n",
       "      <td>-0.047283</td>\n",
       "      <td>0.185068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410455</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>I was going to close my facebook a few months ...</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.080480</td>\n",
       "      <td>0.134324</td>\n",
       "      <td>-0.269117</td>\n",
       "      <td>-0.010553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219012</td>\n",
       "      <td>0.073492</td>\n",
       "      <td>0.065388</td>\n",
       "      <td>0.019547</td>\n",
       "      <td>0.137126</td>\n",
       "      <td>-0.073177</td>\n",
       "      <td>0.013745</td>\n",
       "      <td>-0.090762</td>\n",
       "      <td>0.050335</td>\n",
       "      <td>0.162630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410456</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>30 Seconds to Mars - All of my collections. It...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>0.159443</td>\n",
       "      <td>-0.114777</td>\n",
       "      <td>-0.006862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152720</td>\n",
       "      <td>0.046057</td>\n",
       "      <td>0.063996</td>\n",
       "      <td>0.007415</td>\n",
       "      <td>0.063590</td>\n",
       "      <td>-0.099732</td>\n",
       "      <td>-0.054618</td>\n",
       "      <td>-0.003745</td>\n",
       "      <td>-0.060029</td>\n",
       "      <td>0.083143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410457</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>I have seen it, and i agree. I did actually th...</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.009448</td>\n",
       "      <td>0.166724</td>\n",
       "      <td>-0.247294</td>\n",
       "      <td>-0.151581</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200789</td>\n",
       "      <td>0.064960</td>\n",
       "      <td>-0.039382</td>\n",
       "      <td>-0.041747</td>\n",
       "      <td>0.148716</td>\n",
       "      <td>-0.048417</td>\n",
       "      <td>-0.080719</td>\n",
       "      <td>-0.013402</td>\n",
       "      <td>0.124531</td>\n",
       "      <td>0.174318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410458</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>Ok so i have just watched Underworld 4 (Awaken...</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.013228</td>\n",
       "      <td>0.129549</td>\n",
       "      <td>-0.177374</td>\n",
       "      <td>-0.113464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235097</td>\n",
       "      <td>0.051023</td>\n",
       "      <td>-0.022789</td>\n",
       "      <td>-0.098781</td>\n",
       "      <td>0.156418</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>-0.060064</td>\n",
       "      <td>-0.072731</td>\n",
       "      <td>0.069270</td>\n",
       "      <td>0.100613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410459</td>\n",
       "      <td>INFP</td>\n",
       "      <td>9</td>\n",
       "      <td>I would never want to turn off my emotions. so...</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.020059</td>\n",
       "      <td>0.155645</td>\n",
       "      <td>-0.249107</td>\n",
       "      <td>-0.028219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264817</td>\n",
       "      <td>0.046290</td>\n",
       "      <td>-0.054886</td>\n",
       "      <td>-0.069837</td>\n",
       "      <td>0.109587</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>-0.003390</td>\n",
       "      <td>0.074028</td>\n",
       "      <td>0.104892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410460 rows × 306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Types  id                                              Posts  \\\n",
       "0       INFJ   8  enfp and intj moments    sportscenter not top ...   \n",
       "1       INFJ   8  What has been the most life-changing experienc...   \n",
       "2       INFJ   8                       On repeat for most of today.   \n",
       "3       INFJ   8               May the PerC Experience immerse you.   \n",
       "4       INFJ   8  The last thing my INFJ friend posted on his fa...   \n",
       "...      ...  ..                                                ...   \n",
       "410455  INFP   9  I was going to close my facebook a few months ...   \n",
       "410456  INFP   9  30 Seconds to Mars - All of my collections. It...   \n",
       "410457  INFP   9  I have seen it, and i agree. I did actually th...   \n",
       "410458  INFP   9  Ok so i have just watched Underworld 4 (Awaken...   \n",
       "410459  INFP   9  I would never want to turn off my emotions. so...   \n",
       "\n",
       "        CharCounts  NumberCounts  WordCounts   Vector0   Vector1   Vector2  \\\n",
       "0               65             0          10  0.048666  0.101238 -0.126730   \n",
       "1               61             0          10  0.069644  0.287454 -0.003381   \n",
       "2               28             0           6 -0.109645  0.309563 -0.250297   \n",
       "3               36             0           6  0.262368  0.025354 -0.132030   \n",
       "4              107             0          19  0.070736  0.184186 -0.126542   \n",
       "...            ...           ...         ...       ...       ...       ...   \n",
       "410455         193             0          40  0.080480  0.134324 -0.269117   \n",
       "410456          85             1          18  0.065014  0.159443 -0.114777   \n",
       "410457         199             0          38  0.009448  0.166724 -0.247294   \n",
       "410458         200             1          41 -0.013228  0.129549 -0.177374   \n",
       "410459         112             0          23  0.020059  0.155645 -0.249107   \n",
       "\n",
       "         Vector3  ...  Vector290  Vector291  Vector292  Vector293  Vector294  \\\n",
       "0      -0.103111  ...   0.056108  -0.164767  -0.003561   0.040664   0.101166   \n",
       "1      -0.055506  ...  -0.206936   0.000180  -0.106586  -0.132355   0.153329   \n",
       "2      -0.100388  ...  -0.205930  -0.171407   0.019444  -0.185498   0.014593   \n",
       "3      -0.066374  ...  -0.216144   0.045832  -0.170137  -0.002519   0.065560   \n",
       "4       0.127377  ...  -0.099172   0.030649   0.107528  -0.086214   0.078186   \n",
       "...          ...  ...        ...        ...        ...        ...        ...   \n",
       "410455 -0.010553  ...  -0.219012   0.073492   0.065388   0.019547   0.137126   \n",
       "410456 -0.006862  ...  -0.152720   0.046057   0.063996   0.007415   0.063590   \n",
       "410457 -0.151581  ...  -0.200789   0.064960  -0.039382  -0.041747   0.148716   \n",
       "410458 -0.113464  ...  -0.235097   0.051023  -0.022789  -0.098781   0.156418   \n",
       "410459 -0.028219  ...  -0.264817   0.046290  -0.054886  -0.069837   0.109587   \n",
       "\n",
       "        Vector295  Vector296  Vector297  Vector298  Vector299  \n",
       "0        0.147577  -0.051816   0.038400   0.082892  -0.078360  \n",
       "1        0.067408  -0.021258   0.051582   0.005985  -0.030550  \n",
       "2       -0.031991  -0.028441  -0.097105   0.016200   0.116196  \n",
       "3       -0.067423  -0.240428   0.070806   0.127976  -0.004138  \n",
       "4       -0.070215   0.032399   0.093196  -0.047283   0.185068  \n",
       "...           ...        ...        ...        ...        ...  \n",
       "410455  -0.073177   0.013745  -0.090762   0.050335   0.162630  \n",
       "410456  -0.099732  -0.054618  -0.003745  -0.060029   0.083143  \n",
       "410457  -0.048417  -0.080719  -0.013402   0.124531   0.174318  \n",
       "410458   0.001369  -0.060064  -0.072731   0.069270   0.100613  \n",
       "410459   0.002011   0.004405  -0.003390   0.074028   0.104892  \n",
       "\n",
       "[410460 rows x 306 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaneddf = cleaneddf.drop(['Vectors'],axis = 1)\n",
    "cleaneddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cleaneddf.drop(['Types','id','Posts'],axis = 1)\n",
    "y = cleaneddf['id']\n",
    "labels = cleaneddf['Types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NumberCounts', 'WordCounts', 'Vector3', 'Vector9', 'Vector10', 'Vector12', 'Vector15', 'Vector16', 'Vector20', 'Vector23', 'Vector27', 'Vector28', 'Vector30', 'Vector31', 'Vector32', 'Vector36', 'Vector37', 'Vector38', 'Vector40', 'Vector46', 'Vector49', 'Vector50', 'Vector52', 'Vector55', 'Vector58', 'Vector65', 'Vector69', 'Vector70', 'Vector73', 'Vector74', 'Vector79', 'Vector83', 'Vector86', 'Vector87', 'Vector88', 'Vector89', 'Vector91', 'Vector96', 'Vector97', 'Vector98', 'Vector102', 'Vector103', 'Vector105', 'Vector113', 'Vector116', 'Vector120', 'Vector123', 'Vector124', 'Vector125', 'Vector128', 'Vector131', 'Vector138', 'Vector142', 'Vector143', 'Vector145', 'Vector146', 'Vector148', 'Vector149', 'Vector150', 'Vector152', 'Vector154', 'Vector155', 'Vector159', 'Vector160', 'Vector162', 'Vector164', 'Vector166', 'Vector169', 'Vector170', 'Vector171', 'Vector172', 'Vector173', 'Vector174', 'Vector175', 'Vector176', 'Vector177', 'Vector180', 'Vector181', 'Vector182', 'Vector184', 'Vector187', 'Vector188', 'Vector189', 'Vector190', 'Vector192', 'Vector196', 'Vector198', 'Vector201', 'Vector204', 'Vector207', 'Vector210', 'Vector214', 'Vector221', 'Vector222', 'Vector226', 'Vector229', 'Vector236', 'Vector238', 'Vector240', 'Vector243', 'Vector244', 'Vector249', 'Vector253', 'Vector255', 'Vector262', 'Vector263', 'Vector265', 'Vector266', 'Vector267', 'Vector268', 'Vector270', 'Vector272', 'Vector275', 'Vector277', 'Vector279', 'Vector282', 'Vector286', 'Vector287', 'Vector288', 'Vector289', 'Vector291', 'Vector295']\n"
     ]
    }
   ],
   "source": [
    "#Figures Out Relevant Features and Removes Irrelevant Ones\n",
    "import statsmodels.api as sm\n",
    "cols = list(x.columns)\n",
    "pmax = 1\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = x[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(y,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cleaneddf[selected_features_BE]\n",
    "y = cleaneddf['id']\n",
    "labels = cleaneddf['Types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumberCounts</th>\n",
       "      <th>WordCounts</th>\n",
       "      <th>Vector3</th>\n",
       "      <th>Vector9</th>\n",
       "      <th>Vector10</th>\n",
       "      <th>Vector12</th>\n",
       "      <th>Vector15</th>\n",
       "      <th>Vector16</th>\n",
       "      <th>Vector20</th>\n",
       "      <th>Vector23</th>\n",
       "      <th>...</th>\n",
       "      <th>Vector275</th>\n",
       "      <th>Vector277</th>\n",
       "      <th>Vector279</th>\n",
       "      <th>Vector282</th>\n",
       "      <th>Vector286</th>\n",
       "      <th>Vector287</th>\n",
       "      <th>Vector288</th>\n",
       "      <th>Vector289</th>\n",
       "      <th>Vector291</th>\n",
       "      <th>Vector295</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.103111</td>\n",
       "      <td>1.103382</td>\n",
       "      <td>0.120112</td>\n",
       "      <td>-0.017139</td>\n",
       "      <td>-0.053014</td>\n",
       "      <td>0.195294</td>\n",
       "      <td>-0.009882</td>\n",
       "      <td>-0.192968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>-0.103204</td>\n",
       "      <td>0.149549</td>\n",
       "      <td>-0.301717</td>\n",
       "      <td>0.195879</td>\n",
       "      <td>0.011702</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>0.077249</td>\n",
       "      <td>-0.164767</td>\n",
       "      <td>0.147577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.055506</td>\n",
       "      <td>2.347190</td>\n",
       "      <td>-0.194696</td>\n",
       "      <td>0.062586</td>\n",
       "      <td>-0.121125</td>\n",
       "      <td>-0.174713</td>\n",
       "      <td>-0.011405</td>\n",
       "      <td>-0.096722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.162255</td>\n",
       "      <td>0.119355</td>\n",
       "      <td>-0.118109</td>\n",
       "      <td>0.153282</td>\n",
       "      <td>-0.071058</td>\n",
       "      <td>0.194290</td>\n",
       "      <td>-0.095628</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.067408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.100388</td>\n",
       "      <td>2.271400</td>\n",
       "      <td>-0.224235</td>\n",
       "      <td>0.091262</td>\n",
       "      <td>0.064457</td>\n",
       "      <td>-0.058925</td>\n",
       "      <td>-0.121899</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057559</td>\n",
       "      <td>0.138972</td>\n",
       "      <td>0.282743</td>\n",
       "      <td>-0.005755</td>\n",
       "      <td>0.230963</td>\n",
       "      <td>-0.122787</td>\n",
       "      <td>-0.083324</td>\n",
       "      <td>0.121420</td>\n",
       "      <td>-0.171407</td>\n",
       "      <td>-0.031991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.066374</td>\n",
       "      <td>1.716712</td>\n",
       "      <td>-0.032925</td>\n",
       "      <td>0.019138</td>\n",
       "      <td>-0.185553</td>\n",
       "      <td>-0.181153</td>\n",
       "      <td>0.076267</td>\n",
       "      <td>-0.081551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025825</td>\n",
       "      <td>0.083266</td>\n",
       "      <td>0.056332</td>\n",
       "      <td>0.110999</td>\n",
       "      <td>0.275457</td>\n",
       "      <td>-0.085238</td>\n",
       "      <td>0.284057</td>\n",
       "      <td>0.047923</td>\n",
       "      <td>0.045832</td>\n",
       "      <td>-0.067423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.127377</td>\n",
       "      <td>2.337100</td>\n",
       "      <td>-0.270470</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>0.028919</td>\n",
       "      <td>-0.124201</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.043133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026908</td>\n",
       "      <td>0.037661</td>\n",
       "      <td>0.171206</td>\n",
       "      <td>-0.114109</td>\n",
       "      <td>0.113601</td>\n",
       "      <td>-0.016611</td>\n",
       "      <td>0.021922</td>\n",
       "      <td>-0.009326</td>\n",
       "      <td>0.030649</td>\n",
       "      <td>-0.070215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.010553</td>\n",
       "      <td>2.418188</td>\n",
       "      <td>-0.252297</td>\n",
       "      <td>0.140620</td>\n",
       "      <td>-0.040858</td>\n",
       "      <td>-0.090906</td>\n",
       "      <td>-0.013945</td>\n",
       "      <td>0.020258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.021013</td>\n",
       "      <td>0.214899</td>\n",
       "      <td>-0.026045</td>\n",
       "      <td>0.154671</td>\n",
       "      <td>-0.034403</td>\n",
       "      <td>0.090904</td>\n",
       "      <td>-0.047065</td>\n",
       "      <td>0.073492</td>\n",
       "      <td>-0.073177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410456</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.006862</td>\n",
       "      <td>1.920768</td>\n",
       "      <td>-0.151364</td>\n",
       "      <td>0.085522</td>\n",
       "      <td>-0.121177</td>\n",
       "      <td>-0.123201</td>\n",
       "      <td>-0.068132</td>\n",
       "      <td>-0.058792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030366</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.170454</td>\n",
       "      <td>-0.062679</td>\n",
       "      <td>0.099972</td>\n",
       "      <td>-0.196024</td>\n",
       "      <td>0.108989</td>\n",
       "      <td>-0.027115</td>\n",
       "      <td>0.046057</td>\n",
       "      <td>-0.099732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410457</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.151581</td>\n",
       "      <td>2.414100</td>\n",
       "      <td>-0.194914</td>\n",
       "      <td>0.197825</td>\n",
       "      <td>-0.052595</td>\n",
       "      <td>-0.118497</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>-0.067171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018227</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.295033</td>\n",
       "      <td>-0.016460</td>\n",
       "      <td>0.235071</td>\n",
       "      <td>0.024222</td>\n",
       "      <td>0.122903</td>\n",
       "      <td>-0.065783</td>\n",
       "      <td>0.064960</td>\n",
       "      <td>-0.048417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410458</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.113464</td>\n",
       "      <td>2.278018</td>\n",
       "      <td>-0.167932</td>\n",
       "      <td>0.156542</td>\n",
       "      <td>-0.091218</td>\n",
       "      <td>-0.026859</td>\n",
       "      <td>-0.008995</td>\n",
       "      <td>-0.030206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086333</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.352357</td>\n",
       "      <td>-0.053209</td>\n",
       "      <td>0.145064</td>\n",
       "      <td>-0.110137</td>\n",
       "      <td>0.121512</td>\n",
       "      <td>-0.013895</td>\n",
       "      <td>0.051023</td>\n",
       "      <td>0.001369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410459</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.028219</td>\n",
       "      <td>2.394796</td>\n",
       "      <td>-0.262459</td>\n",
       "      <td>0.142842</td>\n",
       "      <td>-0.059117</td>\n",
       "      <td>-0.166839</td>\n",
       "      <td>0.093334</td>\n",
       "      <td>-0.016811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.026182</td>\n",
       "      <td>0.242607</td>\n",
       "      <td>-0.012288</td>\n",
       "      <td>0.259340</td>\n",
       "      <td>-0.049108</td>\n",
       "      <td>0.061406</td>\n",
       "      <td>-0.099681</td>\n",
       "      <td>0.046290</td>\n",
       "      <td>0.002011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410460 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NumberCounts  WordCounts   Vector3   Vector9  Vector10  Vector12  \\\n",
       "0                  0          10 -0.103111  1.103382  0.120112 -0.017139   \n",
       "1                  0          10 -0.055506  2.347190 -0.194696  0.062586   \n",
       "2                  0           6 -0.100388  2.271400 -0.224235  0.091262   \n",
       "3                  0           6 -0.066374  1.716712 -0.032925  0.019138   \n",
       "4                  0          19  0.127377  2.337100 -0.270470  0.018476   \n",
       "...              ...         ...       ...       ...       ...       ...   \n",
       "410455             0          40 -0.010553  2.418188 -0.252297  0.140620   \n",
       "410456             1          18 -0.006862  1.920768 -0.151364  0.085522   \n",
       "410457             0          38 -0.151581  2.414100 -0.194914  0.197825   \n",
       "410458             1          41 -0.113464  2.278018 -0.167932  0.156542   \n",
       "410459             0          23 -0.028219  2.394796 -0.262459  0.142842   \n",
       "\n",
       "        Vector15  Vector16  Vector20  Vector23  ...  Vector275  Vector277  \\\n",
       "0      -0.053014  0.195294 -0.009882 -0.192968  ...   0.006881  -0.103204   \n",
       "1      -0.121125 -0.174713 -0.011405 -0.096722  ...   0.003520   0.162255   \n",
       "2       0.064457 -0.058925 -0.121899  0.003687  ...  -0.057559   0.138972   \n",
       "3      -0.185553 -0.181153  0.076267 -0.081551  ...  -0.025825   0.083266   \n",
       "4       0.028919 -0.124201  0.004940  0.043133  ...  -0.026908   0.037661   \n",
       "...          ...       ...       ...       ...  ...        ...        ...   \n",
       "410455 -0.040858 -0.090906 -0.013945  0.020258  ...   0.001444   0.021013   \n",
       "410456 -0.121177 -0.123201 -0.068132 -0.058792  ...   0.030366   0.003169   \n",
       "410457 -0.052595 -0.118497  0.161900 -0.067171  ...   0.018227   0.000765   \n",
       "410458 -0.091218 -0.026859 -0.008995 -0.030206  ...   0.086333   0.000032   \n",
       "410459 -0.059117 -0.166839  0.093334 -0.016811  ...   0.007013   0.026182   \n",
       "\n",
       "        Vector279  Vector282  Vector286  Vector287  Vector288  Vector289  \\\n",
       "0        0.149549  -0.301717   0.195879   0.011702   0.008102   0.077249   \n",
       "1        0.119355  -0.118109   0.153282  -0.071058   0.194290  -0.095628   \n",
       "2        0.282743  -0.005755   0.230963  -0.122787  -0.083324   0.121420   \n",
       "3        0.056332   0.110999   0.275457  -0.085238   0.284057   0.047923   \n",
       "4        0.171206  -0.114109   0.113601  -0.016611   0.021922  -0.009326   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "410455   0.214899  -0.026045   0.154671  -0.034403   0.090904  -0.047065   \n",
       "410456   0.170454  -0.062679   0.099972  -0.196024   0.108989  -0.027115   \n",
       "410457   0.295033  -0.016460   0.235071   0.024222   0.122903  -0.065783   \n",
       "410458   0.352357  -0.053209   0.145064  -0.110137   0.121512  -0.013895   \n",
       "410459   0.242607  -0.012288   0.259340  -0.049108   0.061406  -0.099681   \n",
       "\n",
       "        Vector291  Vector295  \n",
       "0       -0.164767   0.147577  \n",
       "1        0.000180   0.067408  \n",
       "2       -0.171407  -0.031991  \n",
       "3        0.045832  -0.067423  \n",
       "4        0.030649  -0.070215  \n",
       "...           ...        ...  \n",
       "410455   0.073492  -0.073177  \n",
       "410456   0.046057  -0.099732  \n",
       "410457   0.064960  -0.048417  \n",
       "410458   0.051023   0.001369  \n",
       "410459   0.046290   0.002011  \n",
       "\n",
       "[410460 rows x 122 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         8\n",
       "1         8\n",
       "2         8\n",
       "3         8\n",
       "4         8\n",
       "         ..\n",
       "410455    9\n",
       "410456    9\n",
       "410457    9\n",
       "410458    9\n",
       "410459    9\n",
       "Name: id, Length: 410460, dtype: int8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22874498530104437\n",
      "0.22682843638844224\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print(logreg.score(X_train, y_train))\n",
    "print(logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0687163994867547\n",
      "0.06725137650440968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "print(gnb.score(X_train, y_train))\n",
    "print(gnb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9848755055303805\n",
      "0.14315645860741608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dct = DecisionTreeClassifier()\n",
    "dct.fit(X_train,y_train)\n",
    "print(dct.score(X_train, y_train))\n",
    "print(dct.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9771930679400348\n",
      "0.1735613701700531\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "print(rfc.score(X_train, y_train))\n",
    "print(rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22128018970585847\n",
      "0.2197534473517517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train,y_train)\n",
    "print(ada.score(X_train, y_train))\n",
    "print(ada.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21155126768341212\n",
      "0.2114700579837256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010970255009872809\n",
      "0.010731439378745322\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "print(lr.score(X_train, y_train))\n",
    "print(lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21175266773863471\n",
      "0.21141158699995127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "cb = BernoulliNB()\n",
    "cb.fit(X_train, y_train)\n",
    "print(cb.score(X_train, y_train))\n",
    "print(cb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010936248158451956\n",
      "0.010827417926285055\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.RidgeCV()\n",
    "reg.fit(X_train, y_train)\n",
    "print(reg.score(X_train, y_train))\n",
    "print(reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "-3.652401007192552e-06\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Lasso()\n",
    "reg.fit(X_train, y_train)\n",
    "print(reg.score(X_train, y_train))\n",
    "print(reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
